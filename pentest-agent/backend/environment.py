from __future__ import annotations

from dataclasses import dataclass, field
from typing import Dict, List, Tuple


ACTIONS = [
    ("scan_port", "passive"),
    ("fingerprint_service", "passive"),
    ("run_passive_check", "passive"),
    ("attempt_exploit_stub_x", "exploitation"),
]


@dataclass
class TargetState:
    ip: str
    open_port: bool = False
    service_detected: bool = False
    attempts: int = 0
    previous_success: bool = False
    vuln_score: float = 0.1
    phase: str = "recon"
    vulnerabilities: List[Dict] = field(default_factory=list)


class PentestEnvironment:
    def __init__(self) -> None:
        self.targets: Dict[int, TargetState] = {}

    def register_target(self, target_id: int, ip: str) -> None:
        self.targets[target_id] = TargetState(ip=ip)

    def state_to_vector(self, target_id: int) -> List[float]:
        """Converts environment state into a compact numeric observation vector.

        Mapping: [open_port_bool, service_detected_bool, num_attempts,
        previous_success_bool, estimated_vulnerability_score].
        """
        t = self.targets[target_id]
        return [
            1.0 if t.open_port else 0.0,
            1.0 if t.service_detected else 0.0,
            float(t.attempts),
            1.0 if t.previous_success else 0.0,
            float(t.vuln_score),
        ]

    def step_passive(self, target_id: int, action: str) -> Tuple[Dict, float]:
        t = self.targets[target_id]
        t.attempts += 1
        if action == "scan_port":
            t.open_port = True
            t.phase = "enumeration"
            reward = -0.05
        elif action == "fingerprint_service":
            t.service_detected = t.open_port
            t.vuln_score = 0.6 if t.service_detected else 0.2
            t.phase = "analysis"
            reward = 0.1
        else:
            t.vulnerabilities.append(
                {
                    "vuln_id": f"SIM-{target_id}-{t.attempts}",
                    "severity": "medium",
                    "description": "Simulated finding from passive analysis",
                    "suggested_action": "attempt_exploit_stub_x",
                }
            )
            reward = 0.05
        return {"phase": t.phase, "vulnerabilities": t.vulnerabilities}, reward

    def apply_exploit_result(self, target_id: int, success: bool, denied: bool = False) -> float:
        """Reward scale: positive for success, small negative for denied, larger for failed attempt."""
        t = self.targets[target_id]
        if denied:
            t.previous_success = False
            return -0.2
        if success:
            t.previous_success = True
            return 1.0
        t.previous_success = False
        return -0.6
